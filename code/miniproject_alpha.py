# -*- coding: utf-8 -*-
"""MiniProject_Alpha.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c277PQvpgwUUMhdgU8RaorbOKgSwq4OS

# Code Progess
"""

import pyspark
import pandas as pd
import numpy as np
import math

from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType, FloatType
from pyspark.sql.functions import col, column
from pyspark.sql.functions import expr
from pyspark.sql.functions import split
from pyspark.sql import Row
from pyspark.mllib.recommendation import ALS

ss=SparkSession.builder.master("local").appName("MiniProject_Alpha").getOrCreate()

data = ss.read.csv("/storage/home/abt5572/Miniproject/wildfiredb.csv.csv", header=True, inferSchema=True)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# chunksize1 = 100000
# df_list = []
# 
# for df in pd.read_csv("wildfiredb.csv", chunksize=chunksize1, engine='python'):
# 
#     df_list.append(df)
#

result = pd.concat(df_list)

pd.set_option('display.max_columns', None)

#result = pd.concat(df_list)
first_df = df_list[0]
first_df.to_csv("small_wildfires.csv")

